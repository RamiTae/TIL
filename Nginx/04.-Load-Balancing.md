# Load Balancing

core networking solution used to distribute traffic across multiple servers in a server farm.

로드 밸런서:

- 클라이언트와 백엔드 서비스 사이에 위치함.
- 클라이언트로부터 요청을 받고, 들어오는 요청을 기반으로 해당 요청을 수행할 수 있는 upstream 서비스 또는 인스턴스로 요청을 전달함.

## HTTP Load Balancing

- Defines a group / pool of servers
- Leverages the proxy_pass directive
- Servers can be defined by
  - UNIX Socket
  - Domain Name
  - IP:Port

## Load Balancing

CONFIGURATION

- upstream directive
  - Describes server pool
  - **Defined in HTTP Context**
- proxy_pass directive forwards request to upstream

NGINX는 사용자가 정의한 로드 밸런싱 방법에 따라 적절한 서버를 선택함
아래의 예에서는 메서드가 정의되지 않았기 때문에 Round Robin 알고리즘을 사용함.

```szh
upstream backend_servers {
  server 10.1.1.4:9001;
  server 10.1.1.4:9002;
}
server {
  listen 80;
    location / {
      proxy_pass  http://backend_servers;
    }
}
```

## Load Balancing - Default method

ROUND ROBIN

- **Round Robin** is the default method
  - Each request is evenly distributed across the pool
- **Server Weights** are taken into consideration to distribute loads across the upstream

- 아래 예시의 요청은 백엔드 서비스 풀 전체에 고르게 분산됨.
- 각각 1의 weight를 가짐 => 각각의 Endpoint에 동일하게 load 됨.
```zsh
upstream backend_servers {
  server 10.1.1.4:9001;
  server 10.1.1.4:9002;
  server 10.1.1.4:9003;
}
```

- 서버에 가중치 할당
```zsh
upstream backend_servers {
  server 10.1.1.4:9001 weight=2;
  server 10.1.1.4:9002 weight=3;
  server 10.1.1.4:9003 weight=5;
}
```